{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9364344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "\n",
    "def normc_initializer(std=1.0):\n",
    "    def initializer(tensor):\n",
    "        tensor.data.normal_(0, 1)\n",
    "        tensor.data *= std / torch.sqrt(tensor.data.pow(2).sum(1, keepdim=True))\n",
    "\n",
    "    return initializer\n",
    "\n",
    "def process_obs(obs):\n",
    "    processed_obs = torch.zeros(obs.shape)\n",
    "    pipe_w = 1/6\n",
    "    bird_w = 25/230\n",
    "    bird_pos = 0.305556 - bird_w\n",
    "    bird_height = 0.06\n",
    "    p_pos1 = obs[0] + pipe_w \n",
    "    p_pos2 = obs[3] + pipe_w \n",
    "    p_pos3 = obs[6] + pipe_w \n",
    "    bird_bottom = obs[9] + 0.06\n",
    "    a, b, c, d = torch.chunk(obs, 4)\n",
    "    if bird_pos < p_pos1:\n",
    "        # Heading to the first pipe\n",
    "        obs = torch.cat((a, b, d), 0)\n",
    "    else:\n",
    "        obs = torch.cat((b, c, d), 0)\n",
    "    return obs\n",
    "    \n",
    "def process_obs_batch(obs_batch):\n",
    "    assert obs_batch.shape[1] == 12\n",
    "    processed = torch.zeros((obs_batch.shape[0], 9))\n",
    "    for i in range(obs_batch.shape[0]):\n",
    "        processed[i] = process_obs(obs_batch[i])\n",
    "    return processed\n",
    "\n",
    "class SlimFC(nn.Module):\n",
    "    \"\"\"Simple PyTorch version of `linear` function\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_size,\n",
    "                 out_size,\n",
    "                 initializer=None,\n",
    "                 activation_fn=True,\n",
    "                 use_bias=True,\n",
    "                 bias_init=0.0):\n",
    "        super(SlimFC, self).__init__()\n",
    "        layers = []\n",
    "        # Actual Conv2D layer (including correct initialization logic).\n",
    "        linear = nn.Linear(in_size, out_size, bias=use_bias)\n",
    "        if initializer:\n",
    "            initializer(linear.weight)\n",
    "        if use_bias is True:\n",
    "            nn.init.constant_(linear.bias, bias_init)\n",
    "        layers.append(linear)\n",
    "        if activation_fn:\n",
    "            activation_fn = nn.ReLU\n",
    "            layers.append(activation_fn())\n",
    "        # Put everything in sequence.\n",
    "        self._model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._model(x)\n",
    "\n",
    "\n",
    "def build_one_mlp(input_size, output_size, hidden_size=256):\n",
    "    return nn.Sequential(\n",
    "        SlimFC(\n",
    "            in_size=input_size,\n",
    "            out_size=hidden_size,\n",
    "            initializer=normc_initializer(1.0),\n",
    "            activation_fn=True\n",
    "        ),\n",
    "        SlimFC(\n",
    "            in_size=hidden_size,\n",
    "            out_size=hidden_size,\n",
    "            initializer=normc_initializer(1.0),\n",
    "            activation_fn=True\n",
    "        ),\n",
    "        SlimFC(\n",
    "            in_size=hidden_size,\n",
    "            out_size=output_size,\n",
    "            initializer=normc_initializer(0.01),  # Make the output close to zero, in the beginning!\n",
    "            activation_fn=False\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.qtable = build_one_mlp(10, 1)\n",
    "\n",
    "    def forward(self, input_obs, input_action):\n",
    "        input_obs = process_obs_batch(input_obs)\n",
    "        return self.qtable(torch.cat((input_obs, input_action.view(-1, 1)), 1))\n",
    "    def compute_action(self, input_obs):\n",
    "        # Compute a single action\n",
    "        input_obs = process_obs(input_obs)\n",
    "        q_zero = self.qtable(torch.cat((input_obs, torch.tensor([0])), 0))\n",
    "        q_one = self.qtable(torch.cat((input_obs, torch.tensor([1])), 0))\n",
    "        if q_zero > q_one:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    def compute_value(self, input_obs):\n",
    "        # Compute a single action\n",
    "        input_obs = process_obs(input_obs)\n",
    "        q_zero = self.qtable(torch.cat((input_obs, torch.tensor([0])), 0))\n",
    "        q_one = self.qtable(torch.cat((input_obs, torch.tensor([1])), 0))\n",
    "        if q_zero > q_one:\n",
    "            return q_zero\n",
    "        else:\n",
    "            return q_one\n",
    "    def explore(self, input_obs, epsilon):\n",
    "        random_num = random.randint(1, 1000)\n",
    "        if random_num < 1000 * epsilon:\n",
    "            return random.choice([0, 1])\n",
    "        else:\n",
    "            return self.compute_action(input_obs)\n",
    "    \n",
    "    \n",
    "    \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a43914",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
