{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0f5c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run network.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dd3448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import gymnasium\n",
    "import flappy_bird_gymnasium\n",
    "from datetime import datetime\n",
    "import torch.optim as optim\n",
    "\n",
    "def main():\n",
    "    # Parameters set up\n",
    "    random.seed(datetime.now().timestamp())\n",
    "    env = gymnasium.make(\"FlappyBird-v0\")\n",
    "    agent = DQN()\n",
    "    optimizer = optim.Adam(agent.parameters(), lr=1e-4)\n",
    "    buffer_size = 10000\n",
    "    num_epochs = 60\n",
    "    max_performance = 85\n",
    "    load_w(agent, optimizer)\n",
    "    for i in range(2000):\n",
    "        print(\"\")\n",
    "        print(\"Iteration \", i)\n",
    "        print(\"Max performance\", max_performance)\n",
    "        train(env, agent, optimizer, buffer_size, num_epochs, 0.1 * (2000-i)/2000)\n",
    "        score = average_score(20, agent)\n",
    "        if score > max_performance:\n",
    "            max_performance = score\n",
    "            save_w(agent, optimizer)\n",
    "    print(\"Max performance is\", max_performance)\n",
    "        \n",
    "def save_w(model, optimizer):\n",
    "    os.makedirs(\"saved_model\", exist_ok=True)\n",
    "    save_path = os.path.join(\"saved_model\", \"DQN.pkl\")\n",
    "    torch.save(dict(\n",
    "        model=model.state_dict(),\n",
    "        optimizer=optimizer.state_dict()\n",
    "    ), save_path)\n",
    "\n",
    "def load_w(model, optimizer):\n",
    "    log_dir = os.path.abspath(os.path.expanduser(\"saved_model\"))\n",
    "    save_path = os.path.join(log_dir, \"DQN.pkl\")\n",
    "    if os.path.isfile(save_path):\n",
    "        state_dict = torch.load(\n",
    "            save_path,\n",
    "            torch.device('cpu') if not torch.cuda.is_available() else None\n",
    "        )\n",
    "        model.load_state_dict(state_dict[\"model\"])\n",
    "        optimizer.load_state_dict(state_dict[\"optimizer\"])\n",
    "        print(\"Successfully loaded weights from {}!\".format(save_path))\n",
    "        return True\n",
    "    else:\n",
    "        raise ValueError(\"Failed to load weights from {}! File does not exist!\".format(save_path))\n",
    "    \n",
    "def train(env, agent, optimizer, buffer_size, num_epochs, e):\n",
    "    with torch.no_grad():\n",
    "        buffer_obs, buffer_action, buffer_t = create_buffer(agent, buffer_size, env, e)\n",
    "    for epoch in range(num_epochs):\n",
    "        sample_size = 5000\n",
    "        obs, action, t = create_samples(buffer_obs, buffer_action, \\\n",
    "                                        buffer_t, buffer_size, sample_size)\n",
    "        qvalues = agent(obs, action)\n",
    "        assert qvalues.requires_grad\n",
    "        l = torch.nn.MSELoss()\n",
    "        loss = l(input=qvalues.view(t.shape), target=t)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "def create_samples(obs, a, t, buffer_size, sample_size):\n",
    "    sample_obs = torch.zeros(obs.shape)\n",
    "    sample_a = torch.zeros(a.shape)\n",
    "    sample_t = torch.zeros(t.shape)\n",
    "    for i in range(sample_size):\n",
    "        random_i = random.randint(0, buffer_size-1)\n",
    "        sample_obs[i] = obs[random_i]\n",
    "        sample_a[i] = a[random_i]\n",
    "        sample_t[i] = t[random_i]\n",
    "    return sample_obs[:sample_size,:], sample_a[:sample_size], sample_t[:sample_size]\n",
    "        \n",
    "\n",
    "def create_buffer(agent, buffer_size, env, e):\n",
    "    # Create buffer\n",
    "    obs_batch = torch.zeros(buffer_size, 12)\n",
    "    action_batch = torch.zeros(buffer_size)\n",
    "    target_batch = torch.zeros(buffer_size)\n",
    "    \n",
    "    # Collect Samples\n",
    "    terminated = True\n",
    "    num = 0\n",
    "    for i in range(buffer_size):\n",
    "        new_episode = terminated\n",
    "        if new_episode:\n",
    "            # if this is a new episode\n",
    "            obs, _ = env.reset()\n",
    "        obs = torch.tensor(obs, dtype=torch.float32)\n",
    "        obs_batch[i] = obs\n",
    "        # Action\n",
    "        action = agent.explore(obs, e)\n",
    "        action_batch[i] = action\n",
    "        obs, reward, terminated, _, info = env.step(action)\n",
    "        if obs[9] < 0:\n",
    "            reward = - 1\n",
    "            terminated = True\n",
    "        if not terminated:\n",
    "            # Q max\n",
    "            obs = torch.tensor(obs, dtype=torch.float32)\n",
    "            pipe_w = 1/6\n",
    "            bird_w = 25/230\n",
    "            bird_pos = 0.305556 - bird_w\n",
    "            bird_height = 0.06\n",
    "            p_pos1 = obs[0] + pipe_w \n",
    "            p_pos2 = obs[3] + pipe_w \n",
    "            p_pos3 = obs[6] + pipe_w \n",
    "            bird_bottom = obs[9]\n",
    "            if bird_pos < p_pos1:\n",
    "                if obs[9] > obs[2]:\n",
    "                    reward = 0.01\n",
    "                elif obs[9] < obs[1] + bird_height:\n",
    "                    reward = 0.01\n",
    "            elif bird_pos < p_pos2:\n",
    "                if obs[9] > obs[5]:\n",
    "                    reward = 0.01\n",
    "                elif obs[9] < obs[4] + bird_height:\n",
    "                    reward = 0.01\n",
    "            else:\n",
    "                raise\n",
    "            q_max = agent.compute_value(obs)\n",
    "            target_batch[i] = reward + q_max\n",
    "        else:\n",
    "            target_batch[i] = reward \n",
    "        if reward > 0.5:\n",
    "            num = num + 1        \n",
    "    print(num)\n",
    "    return obs_batch, action_batch, target_batch\n",
    "\n",
    "def test_performance(agent):\n",
    "    random.seed(datetime.now().timestamp())\n",
    "    env = gymnasium.make(\"FlappyBird-v0\")\n",
    "    seed_number = random.randint(1, 100)\n",
    "    obs, _ = env.reset(seed=seed_number)\n",
    "    total_reward = 0\n",
    "    while True:\n",
    "        # Next action:\n",
    "        # (feed the observation to your agent here)\n",
    "        action = agent.compute_action(torch.tensor(obs, dtype=torch.float32))\n",
    "\n",
    "        # Processing:\n",
    "        obs, reward, terminated, _, info = env.step(action)\n",
    "        total_reward = total_reward + reward\n",
    "        # Checking if the player is still alive\n",
    "        if terminated or info['score'] > 150:\n",
    "            break\n",
    "    env.close()\n",
    "    return info['score']\n",
    "\n",
    "def average_score(runs, agent):\n",
    "    total = 0\n",
    "    for i in range(runs):\n",
    "        total = total + test_performance(agent)\n",
    "    average = total/runs\n",
    "    print(\"average score is \", average)\n",
    "    return average\n",
    "    \n",
    "main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd2fced",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a01503",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
